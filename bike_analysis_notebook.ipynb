{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37172faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "from tools import DataTools\n",
    "# Importing necessary modules\n",
    "from data import Data\n",
    "# Importing necessary modules\n",
    "from datetime import datetime\n",
    "# Importing necessary modules\n",
    "import pandas as pd\n",
    "# Importing necessary modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Importing necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "# Importing necessary modules\n",
    "import seaborn as sns\n",
    "# Importing necessary modules\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b465e8",
   "metadata": {},
   "source": [
    "## üïí Step 1: Define the Date for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "specified_time = \"2022-11-29 10:00\"\n",
    "# Convert string to datetime object\n",
    "specified_time = datetime.strptime(specified_time, \"%Y-%m-%d %H:%M\")\n",
    "# Format the datetime object to extract the year\n",
    "formatted_time = specified_time.strftime(\"%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cae81e",
   "metadata": {},
   "source": [
    "## üìÇ Step 2: Load Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"..\\data_files\"\n",
    "data_directory = r\"..\\data_files\\data\"\n",
    "correct_header_data_bikes = [\"city\", \"id\", \"request_date\", \"datetime\", \"bikes\"]\n",
    "\n",
    "# Open and read data files from the specified directory\n",
    "station_data = DataTools.open_files_in_directory(path, \"bike_station\", \"\\t\")\n",
    "bike_station = Data()\n",
    "# Load the opened data into a Data object\n",
    "bike_station.get_data(station_data)\n",
    "# Filter the data by city or station name\n",
    "bike_station.filter_dataframes(\"city\", [\"amiens\", \"marseille\"])\n",
    "del station_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f5969",
   "metadata": {},
   "source": [
    "## üß™ Step 3: Load Pollution and Weather Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6179d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read data files from the specified directory\n",
    "station_data = DataTools.open_files_in_directory(path, \"pollution_station\", \",\")\n",
    "pollution_station = Data()\n",
    "# Load the opened data into a Data object\n",
    "pollution_station.get_data(station_data)\n",
    "# Filter the data by city or station name\n",
    "pollution_station.filter_dataframes(\"city\", [\"amiens\", \"marseille\"])\n",
    "del station_data\n",
    "\n",
    "# Open and read data files from the specified directory\n",
    "weather_data = DataTools.open_files_in_directory(data_directory, f\"weather_{formatted_time}\", \",\")\n",
    "data_weather = Data()\n",
    "# Load the opened data into a Data object\n",
    "data_weather.get_data(weather_data)\n",
    "# Filter the data by city or station name\n",
    "data_weather.filter_dataframes(\"name\", [\"Amiens\", \"Marseille\"])\n",
    "del weather_data\n",
    "\n",
    "# Open and read data files from the specified directory\n",
    "pollution_data = DataTools.open_files_in_directory(data_directory, f\"pollution_{formatted_time}\", \",\")\n",
    "data_pollution = Data()\n",
    "# Load the opened data into a Data object\n",
    "data_pollution.get_data(pollution_data)\n",
    "# Filter the data by city or station name\n",
    "data_pollution.filter_dataframes(\"name\", [\"Amiens\"])\n",
    "del pollution_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71174b",
   "metadata": {},
   "source": [
    "## üö≤ Step 4: Load and Merge Bike Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341a3733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read data files from the specified directory\n",
    "bike_data = DataTools.open_files_in_directory(data_directory, f\"bike_{formatted_time}\", \"\\t\")\n",
    "# Standardize column headers in the bike data\n",
    "bike_data = DataTools.rename_header(bike_data, correct_header_data_bikes, keep_old_header=True)\n",
    "\n",
    "data_bike = Data()\n",
    "# Load the opened data into a Data object\n",
    "data_bike.get_data(bike_data)\n",
    "# Filter the data by city or station name\n",
    "data_bike.filter_dataframes(\"city\", [\"amiens\", \"marseille\"])\n",
    "del bike_data\n",
    "\n",
    "# Merge additional information (e.g., location, capacity) into bike or pollution data\n",
    "data_bike.data = DataTools.merge_dataframes(\n",
    "    data_bike.data, bike_station.data, \"id\", \"id\", [\"bike_stands\", \"latitude\", \"longitude\", \"id_pollution\"]\n",
    ")\n",
    "\n",
    "# Merge additional information (e.g., location, capacity) into bike or pollution data\n",
    "data_pollution.data = DataTools.merge_dataframes(\n",
    "    data_pollution.data, pollution_station.data, \"id\", \"id\", [\"latitude\", \"longitude\"]\n",
    ")\n",
    "\n",
    "del pollution_station\n",
    "del bike_station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84627907",
   "metadata": {},
   "source": [
    "## üìä Step 5: Calculate Bike Usage Capacity and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of bike slots available in the specified city\n",
    "bike_count_amiens = DataTools.calul_capacity(data_bike.data, \"amiens\")\n",
    "# Calculate the total number of bike slots available in the specified city\n",
    "bike_count_marseille = DataTools.calul_capacity(data_bike.data, \"marseille\")\n",
    "\n",
    "print(f\"Number of slots in Amiens: {bike_count_amiens}\")\n",
    "print(f\"Number of slots in Marseille: {bike_count_marseille}\")\n",
    "\n",
    "# Compute bike usage statistics such as daily and hourly usage\n",
    "dailyuse_amiens, period_use_amiens, useperhour_amiens = DataTools.calculate_use(\n",
    "    data_bike.data[data_bike.data[\"city\"] == \"amiens\"]\n",
    ")\n",
    "# Compute bike usage statistics such as daily and hourly usage\n",
    "dailyuse_marseille, period_use_marseille, useperhour_marseille = DataTools.calculate_use(\n",
    "    data_bike.data[data_bike.data[\"city\"] == \"marseille\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af20ef",
   "metadata": {},
   "source": [
    "## üîç Step 6: Perform Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef9a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform correlation analysis between bike usage and environmental factors\n",
    "DataTools.corr_analysis(\n",
    "    [dailyuse_amiens, data_weather.data],\n",
    "    [\"total_bikes_used\", [\"temp\", \"temp_max\", \"temp_min\", \"humidity\", \"speed\", \"clouds\"]],\n",
    ")\n",
    "\n",
    "# Perform correlation analysis between bike usage and environmental factors\n",
    "DataTools.corr_analysis(\n",
    "    [dailyuse_amiens, data_pollution.data],\n",
    "    [\"total_bikes_used\", [\"NO\", \"NO2\", \"NOX as NO2\", \"O3\", \"PM10\", \"PM2.5\"]],\n",
    ")\n",
    "\n",
    "# Perform correlation analysis between bike usage and environmental factors\n",
    "DataTools.corr_analysis(\n",
    "    [dailyuse_marseille, data_weather.data],\n",
    "    [\"total_bikes_used\", [\"temp\", \"temp_max\", \"temp_min\", \"humidity\", \"speed\", \"clouds\"]],\n",
    ")\n",
    "\n",
    "# Perform correlation analysis between bike usage and environmental factors\n",
    "DataTools.corr_analysis(\n",
    "    [dailyuse_marseille, data_pollution.data],\n",
    "    [\"total_bikes_used\", [\"NO\", \"NO2\", \"NOX as NO2\", \"O3\", \"PM10\", \"PM2.5\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c00c4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = DataTools.predict_bike_usage(\n",
    "    usage_data=dailyuse_amiens, \n",
    "    weather_data=data_weather.data,\n",
    "    pollution_data=data_pollution.data,\n",
    "    threshold=100 # Optional: value above which usage is considered \"high\"\n",
    ")\n",
    "# After calling predict_bike_usage, add the following code to use the results:\n",
    "# Check if the prediction was successful\n",
    "if results and 'error' not in results:\n",
    "    print(\"\\n===== USING PREDICTION RESULTS =====\")\n",
    "    \n",
    "    # 1. Access the regression model metrics\n",
    "    if 'regression' in results:\n",
    "        reg_metrics = results['regression']\n",
    "        print(f\"Regression model R¬≤ score: {reg_metrics['r2']:.4f}\")\n",
    "        print(f\"RMSE: {reg_metrics['rmse']:.2f} bikes\")\n",
    "        \n",
    "        # Make a prediction with the regression model for a new data point\n",
    "        # Example: predict bike usage for a specific set of features\n",
    "        new_data = pd.DataFrame({\n",
    "            'day_of_week': [0],  # Monday\n",
    "            'month': [6],        # June\n",
    "            'is_weekend': [0],   # Not weekend\n",
    "            'temp': [25],        # 25¬∞C\n",
    "            'humidity': [50]     # 50% humidity\n",
    "            # Add other features as needed\n",
    "        })\n",
    "        \n",
    "        # Make sure to use only the features that the model was trained on\n",
    "        missing_cols = set(reg_metrics['features']) - set(new_data.columns)\n",
    "        for col in missing_cols:\n",
    "            new_data[col] = 0  # Fill missing columns with default values\n",
    "            \n",
    "        new_data = new_data[reg_metrics['features']]  # Reorder columns\n",
    "        \n",
    "        # Scale the data using the same scaler used for training\n",
    "        scaled_data = reg_metrics['scaler'].transform(new_data)\n",
    "        \n",
    "        # Make prediction\n",
    "        predicted_usage = reg_metrics['model'].predict(scaled_data)[0]\n",
    "        print(f\"Predicted bike usage for a 25¬∞C Monday in June: {predicted_usage:.0f} bikes\")\n",
    "    \n",
    "    # 2. Use the classification model for high/low usage prediction\n",
    "    if 'classification' in results:\n",
    "        print(\"\\nBinary classification performance:\")\n",
    "        print(f\"Accuracy: {results['classification']['accuracy']:.2f}\")\n",
    "        \n",
    "        # You could predict if usage will be high or low for new data\n",
    "        if reg_metrics and 'model' in results['classification']:\n",
    "            high_usage = results['classification']['model'].predict(scaled_data)[0]\n",
    "            print(f\"High usage day? {'Yes' if high_usage else 'No'}\")\n",
    "    \n",
    "    # 3. Use the category classification model\n",
    "    if 'category_classification' in results:\n",
    "        print(\"\\nCategory classification performance:\")\n",
    "        print(f\"Accuracy: {results['category_classification']['accuracy']:.2f}\")\n",
    "        \n",
    "        # Predict usage category (low/medium/high) for new data\n",
    "        if reg_metrics and 'model' in results['category_classification']:\n",
    "            category = results['category_classification']['model'].predict(scaled_data)[0]\n",
    "            print(f\"Usage category: {category}\")\n",
    "    \n",
    "    # 4. You could save the models for future use\n",
    "# Importing necessary modules\n",
    "    import pickle\n",
    "    \n",
    "    # Save regression model\n",
    "    if 'regression' in results:\n",
    "        with open('bike_usage_regression_model.pkl', 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'model': results['regression']['model'],\n",
    "                'scaler': results['regression']['scaler'],\n",
    "                'features': results['regression']['features']\n",
    "            }, f)\n",
    "        print(\"\\nRegression model saved to 'bike_usage_regression_model.pkl'\")\n",
    "        \n",
    "    print(\"\\n===== END OF RESULTS USAGE =====\")\n",
    "else:\n",
    "    print(\"Prediction failed or returned no results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ba700c",
   "metadata": {},
   "source": [
    "## ‚úÖ Final Step: Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c10840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly free memory\n",
    "gc.collect()\n",
    "print(\"Program completed successfully. Memory freed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
